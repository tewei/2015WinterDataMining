{
 "metadata": {
  "name": "",
  "signature": "sha256:58f99060cb4a1395f714821550bef9b2c08e90a5ca705cddbd3d76ca6cb9edbf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "#Serialization\n",
      "import gzip\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "\n",
      "import numpy as np\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "#Logistic Regression Model P(x is a member of i) = softmaxi(Wx + b)\n",
      "class LR(object):\n",
      "    def __init__(self, input, n_in, n_out):\n",
      "        #n_in: input dimension, n_out: ouptut dimension\n",
      "        self.W = theano.shared(value=np.zeros(n_in, n_out), dtype=theano.config.floatX),name='W', borrow=True) \n",
      "        self.b = theano.shared(value=np.zeros(n_out, ), dtype=theano.config.floatX),name='b', borrow=True)\n",
      "        self.Pyx = T.nnet.softmax(T.dot(input, self.W)+self.b)\n",
      "        self.Ypred = T.argmax(self.Pyx, axis=1)\n",
      "        self.params = [self.W, self.b]\n",
      "        \n",
      "    def NegLogLike(self, y):\n",
      "        #Minimizing Description Length of y\n",
      "        return -T.mean(T.log(self.Pyx)[T.arange(y.shape[0]), y])\n",
      "\n",
      "    def errors(self, y):\n",
      "        if y.ndim != self.Ypred.ndim:\n",
      "            #y\u61c9\u8a72\u8ddfYpred\u540c\u578b\n",
      "            raise TypeError('y', y.type, 'Ypred', self.Ypred.type)\n",
      "        if y.dtype.startswith('int'):\n",
      "            return T.mean(T.neq(self.Ypred, y))\n",
      "        else:\n",
      "            raise NoImplementedError()\n",
      "        \n",
      "x = T.matrix('x') #data\n",
      "y = T.ivector('y') #label\n",
      "\n",
      "#MNIST image is 28*28\n",
      "cls = LR(input=x, n_in=28*28, n_out=10)\n",
      "cost = classifier.NegLogLike(y)\n",
      "\n",
      "#Mini-batch Stochastic Gradient Decent\n",
      "gW = T.grad(cost=cost, wrt=cls.W)\n",
      "gb = T.grad(cost=cost, wrt=cls.b)\n",
      "updates = [(cls.W, cls.W - LearnRate*gW), (cls.b, cls.b - LearnRate*gb)]\n",
      "\n",
      "def load_data(dataset):\n",
      "    f = gzip.open(dataset, 'rb')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "train_mod = theano.function(\n",
      "    inputs=[index], \n",
      "    outputs=cost, \n",
      "    updates=updates, \n",
      "    givens={\n",
      "        x: TrainSetX[index*Size: (index+1)*Size],\n",
      "        y: TrainSetY[index*Size: (index+1)*Size]\n",
      "    }\n",
      ")\n",
      "\n",
      "test_mod = theano.function(\n",
      "    inputs=[index], \n",
      "    outputs=cost, \n",
      "    updates=updates, \n",
      "    givens={\n",
      "        x: TrainSetX[index*Size: (index+1)*Size],\n",
      "        y: TrainSetY[index*Size: (index+1)*Size]\n",
      "    }\n",
      ")\n",
      "\n",
      "valid_mod = theano.function(\n",
      "    inputs=[index], \n",
      "    outputs=cost, \n",
      "    updates=updates, \n",
      "    givens={\n",
      "        x: TrainSetX[index*Size: (index+1)*Size],\n",
      "        y: TrainSetY[index*Size: (index+1)*Size]\n",
      "    }\n",
      ")\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}